{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from makedataset import makedataset\n",
    "from root_numpy import array2root\n",
    "from numpy.testing._private.utils import HAS_LAPACK64\n",
    "from tensorflow.python.keras.saving.save import load_model\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "\n",
    "import numpy as np\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['geninvis_px', 'geninvis_py', 'geninvis_pz', 'geninvis_e', 'genmuon_px', 'genmuon_py', 'genmuon_pz', 'genmuon_e', 'muon_px', 'muon_py', 'muon_pz', 'muon_e', 'invis_px', 'invis_py', 'boson_M']\n",
      "---------------  dimensions of the input variables  ---------------\n",
      "training   input dimensions (10000, 8)    (10000,)\n",
      "predicitng input dimensions (10000, 6)\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data = makedataset('W2LNu10000Events_13Tev.root')\n",
    "\n",
    "X_train = data.getGenFeatureVals()\n",
    "y_train = data.getGenLabelVals()\n",
    "X_star  = data.getRecoFeatureVals()\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "print('-'*15,' dimensions of the input variables ','-'*15)\n",
    "print('training   input dimensions',X_train.shape,'  ',y_train.shape)\n",
    "print('predicitng input dimensions',X_star.shape)\n",
    "print('-'*50)\n",
    "num_pipeline = Pipeline([\n",
    "    #('imputer',SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "X_gen,X_reco = num_pipeline.fit_transform(X_train),num_pipeline.fit_transform(X_star)\n",
    "M_gen  = num_pipeline.fit_transform(y_train.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "class RecoVariables:\n",
    "    def __init__(self,genData,recoData):\n",
    "        self.genData  = genData\n",
    "        self.recoData = recoData\n",
    "        path_to_directory = self.setPath('default')\n",
    "        print(f'plots are save {path_to_directory} directory')\n",
    "        try:\n",
    "            os.mkdir(path_to_directory)\n",
    "        except:\n",
    "            print('plots folder is already created')\n",
    "\n",
    "        if(genData.shape[0] != recoData.shape[0]):\n",
    "            print('datasets are not in same direction')\n",
    "        \n",
    "            \n",
    "    def train(self,n_epoch,batch_size,sample_interval=10):\n",
    "        half_batch = int(batch_size/2.0)\n",
    "        self.ix = np.random.randint(0,self.gen_px.shape[0],half_batch)\n",
    "        discriminator = self.build_discriminator(2)\n",
    "        generator     = self.build_generator(1,1)\n",
    "        gan           = self.build_gan(generator,discriminator)\n",
    "        min_sep = 10**4\n",
    "        # for i in range(1,n_epoch+1):\n",
    "        #     xreal,yreal = self.generate_real_samples(half_batch)\n",
    "        #     xfake,yfake = self.generate_fake_samples(generator,half_batch)\n",
    "        #     discriminator.train_on_batch(xreal,yreal)\n",
    "        #     discriminator.train_on_batch(xfake,yfake)\n",
    "        #     [xgan,label_gan] = self.generate_latent_samples()\n",
    "        #     ygan = np.ones((half_batch,1))\n",
    "        #     gan.train_on_batch([xgan,label_gan],ygan)\n",
    "        #     self.gan_px = self.eval(generator)\n",
    "            \n",
    "\n",
    "    def jointPzE(self,noise_kin):\n",
    "        pz = noise_kin[:,-2]\n",
    "        E  = np.sqrt(self.recoData[-2]**2 + self.recoData[-1]**2 + pz**2)\n",
    "        new_kin = np.concatenate((self.recoDataset,pz.reshape(-1,1),E.reshape(-1,1)),axis=1)\n",
    "        return new_kin\n",
    "    \n",
    "    def hist_area(self,hist,nbins):\n",
    "        n,bins = np.histogram(hist,nbins)\n",
    "        power = abs(bins[0]-bins[1])*sum(n)/2\n",
    "        return power\n",
    "\n",
    "    def predict_pz(self,gen_pz):\n",
    "        g_model = load_model('ganGenerator.h5')\n",
    "        pz = np.random.normal(0,0.4,gen_pz.shape[0])\n",
    "        gen_input = [gen_pz,pz]\n",
    "        gen_output = g_model.predict(gen_input)\n",
    "        pred = gen_output-gen_pz.reshape(-1,1)\n",
    "        return pred\n",
    "\n",
    "    def eval(self,generator):\n",
    "        self.noise = np.random.uniform(0,0.1,self.gen_px.shape[0])\n",
    "        xgen  = generator.predict([self.gen_px,self.noise])\n",
    "        return xgen-self.gen_px.reshape(-1,1)\n",
    "\n",
    "    def generate_real_samples(self,n):\n",
    "        xreal = np.concatenate((self.gen_px[self.ix].reshape(-1,1),self.reco_px[self.ix].reshape(-1,1)),axis=1)\n",
    "        yreal = np.ones((n,1))\n",
    "        return xreal,yreal\n",
    "\n",
    "    def generate_latent_samples(self):\n",
    "        noise = np.random.uniform(0,1,self.gen_px.shape[0])\n",
    "        return [self.gen_px[self.ix],noise[self.ix]]\n",
    "\n",
    "    def generate_fake_samples(self,generator,n):\n",
    "        [xinput,zinput] = self.generate_latent_samples()\n",
    "        xgen = generator.predict([xinput,zinput])\n",
    "        xfake = np.concatenate((xinput.reshape(-1,1),xgen-xinput.reshape(-1,1)),axis=1)\n",
    "        yfake = np.zeros((n,1))\n",
    "        return xfake,yfake\n",
    "\n",
    "    def setPath(self,path):\n",
    "        if(path == 'default'):\n",
    "            self.path = '/mnt/e/ML_massfit/plots/plots_fromPzProducer'\n",
    "        else:\n",
    "            self.path = path\n",
    "        return self.path\n",
    "\n",
    "    def build_generator(self,input_dim,output_dim):\n",
    "        gen_input   = Input(shape=(input_dim,))\n",
    "        y_input = Input(shape=(1,))\n",
    "        merge = Concatenate()([gen_input,y_input])\n",
    "        layer = Dense(64,activation='relu')(merge)\n",
    "        layer = Dense(256,activation='relu')(layer)\n",
    "        layer = Dense(64,activation='relu')(layer)\n",
    "        out_layer = Dense(output_dim,activation='tanh')(layer)\n",
    "        model = Model([gen_input,y_input],out_layer,name='autoencoder')\n",
    "        plot_model(model,to_file=self.path+'/Generator_model_summary.png',\n",
    "            show_shapes=True,show_layer_names=True)\n",
    "        return model\n",
    "\n",
    "    def build_discriminator(self,n_inputs):\n",
    "        gen_output = Input(shape=(n_inputs,))\n",
    "        y_output   = Input(shape=(1,))\n",
    "        merge   = Concatenate()([gen_output,y_output])\n",
    "        layer = Dense(128,activation='relu')(merge)\n",
    "        layer = Dense(64,activation='relu')(layer)\n",
    "        layer = Dense(32,activation='relu')(layer)\n",
    "        out_layer = Dense(1,activation='sigmoid')(layer)\n",
    "        model = Model([gen_output,y_output], out_layer)\n",
    "        opt = Adam(lr=0.00002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "            optimizer=opt, metrics=['accuracy'])\n",
    "        plot_model(model,to_file=self.path+'/Discriminator_model_summary.png',\n",
    "            show_shapes=True,show_layer_names=True)\n",
    "        return model\n",
    "\n",
    "    def build_gan(self,generator,discriminator):\n",
    "        discriminator.trainable = False\n",
    "        input_gen,input_true = generator.input\n",
    "        output_reco =  generator.output\n",
    "        print(type(output_reco))\n",
    "        out_array = K.eval(output_reco)\n",
    "        reco_input = self.jointPzE(out_array)\n",
    "        gen_output = [reco_input,input_true]\n",
    "        gan_output = discriminator(gen_output)\n",
    "        model = Model([input_gen,input_true],gan_output)\n",
    "        opt = Adam(lr=0.00002, beta_1=0.5)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "        plot_model(model,to_file=self.path+'/GAN_model_summary.png',\n",
    "            show_shapes=True,show_layer_names=True)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plots are save /mnt/e/ML_massfit/plots/plots_fromPzProducer directory\n",
      "plots folder is already created\n"
     ]
    }
   ],
   "source": [
    "reco_obj = RecoVariables(X_gen,X_reco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vinay/miniconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.engine.keras_tensor.KerasTensor'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'KerasTensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-397d9fa413ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreco_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mreco_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreco_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-69df0461de55>\u001b[0m in \u001b[0;36mbuild_gan\u001b[0;34m(self, generator, discriminator)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0moutput_reco\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_reco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mout_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_reco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mreco_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjointPzE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgen_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mreco_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36meval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m   \"\"\"\n\u001b[0;32m-> 1517\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1518\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/keras/backend.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3675\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3676\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3677\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3678\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_in_graph_mode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3679\u001b[0m     \u001b[0;31m# This is a variable which was created in an eager context, but is being\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasTensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "discriminator = reco_obj.build_discriminator(8)\n",
    "generator     = reco_obj.build_generator(8,8)\n",
    "gan = reco_obj.build_gan(generator,discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../data/W2LNu10000Events_13Tev_new.root'\n",
    "leaf = zip(recopz,recoE)\n",
    "leaf_l = list(leaf)\n",
    "branch = np.array(leaf_l,dtype=[('invis_pz','float32'),('invis_e','float32')])\n",
    "array2root(branch,filename,treename='analysisTree',mode='update')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = tf.one_hot(train_labels, depth=10)\n",
    "type(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = tf.constant([1,2,3],dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
       "array([[1.],\n",
       "       [2.],\n",
       "       [3.]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(te,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 4., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3c58c18f5321ddae34912d06bfde31b7f245b0b9ebb55944eb6e4ac82c7ab293"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
